#+TITLE: 5D-GAI Intensive Development Guide
#+AUTHOR: Jason Walsh
#+EMAIL: j@wal.sh
#+DATE: March 30, 2025

* Development Guide
:PROPERTIES:
:VISIBILITY: all
:END:

** :important: Git Conventions
:PROPERTIES:
:CUSTOM_ID: git-conventions
:END:

- *Commits*: Use Conventional Commits format: ~<type>(<scope>): <description>~
- *Types*: feat, fix, docs, style, refactor, test, chore
- *Example*: ~feat(api): add Gemini client implementation~
- *Attribution*: ALWAYS use ~--trailer~ flag for attribution, NOT inline in the message
  #+begin_src bash
  git commit -m "feat(client): add support for system instructions" \
    --trailer "Co-authored-by: Claude <claude@anthropic.com>" \
    --trailer "Signed-off-by: jwalsh <j@wal.sh>" \
    --trailer "LLM-version: 3.7"
  #+end_src

** Build & Test Commands
:PROPERTIES:
:CUSTOM_ID: build-test
:END:

We use a Makefile to simplify common tasks. Run =make= without arguments to see available commands.

#+begin_src bash
# Show available commands
make

# Setup the environment
make setup

# Start development shell
make dev

# Run tests
make test

# Test API connectivity
make api-test
#+end_src

Additional commands:

- Setup environment: ~poetry install~ and ~poetry shell~
- Run Python scripts: ~python src/script_name.py~
- Run Jupyter: ~jupyter notebook~ or ~jupyter lab~
- Import module: ~from src.gemini_client import GeminiClient~
- Environment setup: ~source .env~ (create from config/.envrc.template)

** Org-mode and Source File Generation
:PROPERTIES:
:CUSTOM_ID: org-mode
:END:

The repository uses Org-mode for literate programming, with source code tangled from Org files.

*** File-based Dependency System

The Makefile implements a file-based dependency system to ensure efficient tangling:

- Every ~.org~ file can generate ~.py~ and ~.hy~ source files
- Source files are only regenerated when their Org files change (timestamp checking)
- Pattern rule: ~%.py %.hy: %.org~ manages dependencies automatically

*** Build Commands

- Tangle a specific file: ~make tangle FILE=path/to/file.org~
- Tangle all files at once: ~make tangle-all~
- Full build with dependencies: ~make build~
- Force rebuild all sources: ~touch .tangled_sources && make build~

*** Script Integration

The Makefile uses the following scripts:
- ~scripts/tangle-org.sh~: Tangles a single Org file
- ~scripts/tangle-all.sh~: Tangles all Org files in the project

** Code Style Guidelines
:PROPERTIES:
:CUSTOM_ID: code-style
:END:

*** Python Coding Standards

Style settings are configured in ~.style.yapf~:
- Based on Google style
- 4-space indentation
- 100 character line limit

*** Type Annotations

All functions must have proper type annotations:

#+begin_src python
from typing import Dict, List, Any, Optional

def process_data(input_data: List[Dict[str, Any]], limit: Optional[int] = None) -> Dict[str, Any]:
    """Process the input data and return results.
    
    Args:
        input_data: List of data dictionaries to process
        limit: Optional limit on number of results
        
    Returns:
        Dictionary containing processed results
    """
    # Implementation
    pass
#+end_src

*** Docstrings

Use Google-style docstrings with Args/Returns sections:

#+begin_src python
def calculate_score(values: List[float], weights: Optional[List[float]] = None) -> float:
    """Calculate weighted score from provided values.
    
    Args:
        values: List of float values to score
        weights: Optional weights to apply (defaults to equal weighting)
        
    Returns:
        Float representing the calculated score
        
    Raises:
        ValueError: If values is empty or weights length doesn't match values
    """
    # Implementation
    pass
#+end_src

*** Imports

Group imports in the following order, with a blank line between groups:

#+begin_src python
# Standard library
import os
import json
from typing import Dict, List, Any

# Third-party libraries
import numpy as np
import requests
from dotenv import load_dotenv

# Local modules
from src.utils import format_response
from src.constants import API_TIMEOUT
#+end_src

*** Error Handling

Use specific exceptions and proper context managers:

#+begin_src python
try:
    response = requests.get(url, timeout=5)
    response.raise_for_status()
    return response.json()
except requests.exceptions.HTTPError as err:
    logger.error(f"HTTP error: {err}")
    raise
except requests.exceptions.ConnectionError:
    logger.error(f"Connection error for URL: {url}")
    raise
except requests.exceptions.Timeout:
    logger.error("Request timed out")
    raise
except requests.exceptions.RequestException as err:
    logger.error(f"Unexpected error: {err}")
    raise
#+end_src

*** Naming Conventions

- Variables and functions: ~snake_case~
- Classes: ~PascalCase~
- Constants: ~UPPER_CASE~
- Private methods/variables: ~_leading_underscore~

** Docker Usage
:PROPERTIES:
:CUSTOM_ID: docker
:END:

*** Building and Running

The ~docker-scripts/run.sh~ script provides commands for building and running containers:

- Build all containers: ~docker-compose build~
- Run Jupyter: ~docker-compose up notebook~
- Run API: ~docker-compose up api~
- Run all services: ~docker-compose up~

** Data Management
:PROPERTIES:
:CUSTOM_ID: data
:END:

*** Environment Variables

The ~config/.envrc.template~ file defines the required environment variables:

- API Keys (AI_STUDIO_API_KEY, KAGGLE_USERNAME, KAGGLE_KEY, etc.)
- Optional Google Cloud settings
- PYTHONPATH configuration

Copy this template to create your ~.env~ file in the project root.

** Contributing
:PROPERTIES:
:CUSTOM_ID: contributing
:END:

*** Getting Started

1. Fork the repository
2. Clone your fork: ~git clone https://github.com/yourusername/5dgai-intensive.git~
3. Set up the environment: ~make setup~
4. Create a new branch: ~git checkout -b feature/your-feature-name~
5. Make your changes
6. Run linters and tests: ~make lint~ and ~make test~
7. Commit with appropriate format (see [[#git-conventions][Git Conventions]])
8. Push to your fork and submit a pull request

*** Development Workflow

1. Use [[file:CLAUDE.org][CLAUDE.org]] for guidance on repository standards
2. Follow proper Org-mode documentation practices
3. Create test files for any new functionality
4. Document changes in appropriate Org files
5. Run ~make lint-all~ before submitting changes
6. Ensure Docker containers still build properly

*** Full Command Reference

| Command             | Description                                      |
|---------------------+--------------------------------------------------|
| ~make setup~        | Setup Python environment with Poetry             |
| ~make dev~          | Start Poetry shell for development               |
| ~make api-test~     | Test API connectivity with Gemini                |
| ~make lint~         | Run all linters (Python, Shell, Org, Elisp)      |
| ~make lint-py~      | Lint Python files specifically                   |
| ~make lint-sh~      | Lint shell scripts specifically                  |
| ~make lint-org~     | Lint Org mode files                              |
| ~make lint-el~      | Lint Emacs Lisp files                            |
| ~make format~       | Format all code files                            |
| ~make format-py~    | Format Python files with black and isort         |
| ~make format-sh~    | Format shell scripts with shfmt                  |
| ~make tangle~       | Tangle a specific org file                       |
| ~make tangle-all~   | Tangle all org files in the project              |
| ~make build~        | Build all source files from Org files            |
| ~make lint-all~     | Run comprehensive linting with lint-all.sh       |
| ~make test~         | Run tests                                        |
| ~make docker~       | Build all Docker containers                      |
| ~make docker-jupyter~ | Run Jupyter notebook server in Docker          |
| ~make docker-api~   | Run API service in Docker                        |

*** Technology Migration Plans

The repository is currently in Python but planning to migrate to Hy (Lisp dialect that runs on Python runtime).
See existing GitHub issues for progress updates on this migration.