#+TITLE: 5-Day Gen AI Intensive Course
#+AUTHOR: Jason Walsh
#+EMAIL: j@wal.sh
#+DATE: March 30, 2025

#+ATTR_HTML: :width 100% :alt 5-Day Generative AI Intensive Banner
[[file:images/gemini/course-banners/course-timeline-banner-gemini.jpeg]]

#+begin_html
<p>
  <a href="https://python.org"><img src="https://img.shields.io/badge/python-3.11-blue.svg" alt="Python Version"></a>
  <a href="https://python-poetry.org/"><img src="https://img.shields.io/badge/poetry-managed-blueviolet" alt="Poetry"></a>
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
</p>
#+end_html

* Course Overview

Welcome to the Google's 5-Day Generative AI Intensive course companion repository! This toolkit helps you:

- üöÄ Hit the ground running with pre-configured environments
- üîå Connect to Google AI Studio APIs quickly with minimal setup
- üìä Focus on learning instead of debugging environment issues
- üìù Keep your notes organized by course day
- üîç Explore bonus examples beyond what's covered in the course

*Note*: While the official course uses Python and Jupyter Notebooks, this repository 
takes a different approach using *Hy* (a Lisp dialect that runs on Python) and *Org-mode* 
for literate programming. The core functionality and concepts remain the same, but with 
the elegance of Lisp syntax and the power of Org-mode's tangling capabilities.

* What You'll Learn in the Course

- *Day 1*: Foundational Large Language Models & Text Generation + Prompt Engineering 
- *Day 2*: Embeddings and Vector Stores/Databases
- *Day 3*: Generative AI Agents and Agents Companion
- *Day 4*: Domain-Specific LLMs and Fine-tuning
- *Day 5*: Production deployment and advanced use cases

* Quick Start Guide

** Setup your environment
   #+begin_src sh
   # Using make (recommended approach)
   make setup
   
   # Start development environment after setup
   make dev
   #+end_src
   
   *Note*: Always prefer using `make` commands over direct scripts or tool calls. The Makefile provides 
   consistent, tested, and maintainable operations for all project tasks.

** Configure your API keys
   Edit the ~.env~ file to add your API keys:
   #+begin_src sh
   AI_STUDIO_API_KEY="your-key-here"
   KAGGLE_USERNAME="your-username"
   KAGGLE_KEY="your-key"
   # Optional keys for additional exercises
   OPENAI_API_KEY=""
   ANTHROPIC_API_KEY=""
   #+end_src

** Work with Org-mode Notebooks
   #+begin_src sh
   # Start the development environment first
   make dev
   
   # Tangle code from a specific notebook
   make tangle FILE=notebooks/day1/01-introduction.org
   
   # Tangle all notebooks and build source files
   make build
   
   # Run tests after making changes
   make test
   #+end_src
   
   *Note*: The Makefile handles environment setup, dependencies, and execution context.
   Always use `make` commands rather than direct tool invocation to ensure consistent behavior.

** Test your API connectivity
   #+begin_src sh
   # Quick validation of your Gemini API setup
   make api-test
   #+end_src

* Repository Tools & Features

- *Gemini API Client*: Ready-to-use Hy/Python interface to Google's Gemini models
- *Org-mode Notebooks*: Organized by course day for easy learning & tangling
- *Restclient Integration*: Direct API testing in Org-mode with ob-restclient
- *IPython Support*: Enhanced REPL experience for both Python and Hy
- *Resource Collection*: Papers, references, and supplementary materials
- *Docker Integration*: Containerized environment to avoid compatibility issues
- *Automated Testing*: Verify API connectivity with a single command

* Core Features Demonstrated

- Text generation with Gemini models
- Prompt engineering techniques and evaluation
- Embeddings and vector similarity search
- RAG (Retrieval Augmented Generation) implementations
- Function calling and agentic systems with LangGraph
- Fine-tuning custom models for domain-specific tasks
- Google Search grounding for real-time information

* Using the Gemini Client

Our simplified client makes it easy to interact with Gemini models using Hy:

#+begin_src hy
(import [src.gemini-client [GeminiClient]])

;; Initialize with API key from .env file
(setv client (GeminiClient))

;; Simple text generation
(setv response (.generate-content client 
    "Explain the concept of attention in transformer models."))
(print (.extract-text client response))

;; Chat conversation
(setv messages [
    {"role" "user" "content" "What are three applications of generative AI?"}
    {"role" "model" "content" "1. Content creation\n2. Code generation\n3. Data augmentation"}
    {"role" "user" "content" "Elaborate on code generation use cases."}
])
(setv chat-response (.chat client messages))
(print (.extract-text client chat-response))
#+end_src

* Course Day-by-Day Navigation

** [[file:notebooks/day1/01-introduction.org][Day 1: Foundational LLMs & Prompt Engineering]]

- Foundational Large Language Models and Text Generation
- Prompt Engineering techniques and best practices
- Codelabs: 
  - [[https://www.kaggle.com/code/markishere/day-1-prompting][Prompting fundamentals]]
  - [[https://www.kaggle.com/code/markishere/day-1-evaluation-and-structured-output][Evaluation and structured output]]
- Whitepapers:
  - [[https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation][Foundational LLM and Text Generation]] ([[file:whitepapers/llm_endnotes.pdf][Endnotes]])
  - [[https://www.kaggle.com/whitepaper-prompt-engineering][Prompt Engineering]] ([[file:whitepapers/prompt_engineering_endnotes.pdf][Endnotes]])

** [[file:notebooks/day2/01-prompt-engineering.org][Day 2: Embeddings and Vector Stores]]

- Embeddings concepts and applications
- Vector databases and similarity search
- Codelabs:
  - [[https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag][Document Q&A with RAG]]
  - [[https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores][Embeddings and similarity scores]]
  - [[https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras][Classifying embeddings with Keras]]
- Whitepapers:
  - [[https://www.kaggle.com/whitepaper-embeddings-and-vector-stores][Embeddings and Vector Stores]] ([[file:whitepapers/embeddings_endnotes.pdf][Endnotes]])

** [[file:notebooks/day3/01-building-with-api.org][Day 3: Generative AI Agents]]

- Core components of AI agents
- Iterative development process for agents
- Codelabs:
  - [[https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph][Building an agent with LangGraph]]
  - [[https://www.kaggle.com/code/markishere/day-3-function-calling-with-the-gemini-api][Function calling with Gemini API]]
- Whitepapers:
  - [[https://www.kaggle.com/whitepaper-agents][Generative AI Agents]] ([[file:whitepapers/agents_endnotes.pdf][Endnotes]])
  - [[https://www.kaggle.com/whitepaper-agent-companion][Agent Companion]] ([[file:whitepapers/agents_companion_endnotes.pdf][Endnotes]])

** [[file:notebooks/day4/01-fine-tuning-a-custom-model.org][Day 4: Domain-Specific LLMs]]

- Creating specialized LLMs like SecLM and MedLM/Med-PaLM
- Fine-tuning models for domain-specific tasks
- Codelabs:
  - [[https://www.kaggle.com/code/markishere/day-4-fine-tuning-a-custom-model][Fine-tuning a custom model]]
  - [[https://www.kaggle.com/code/markishere/day-4-google-search-grounding][Google Search grounding]]
- Whitepapers:
  - [[https://www.kaggle.com/whitepaper-solving-domains-specific-problems-using-llms][Solving Domain-Specific Problems Using LLMs]] ([[file:whitepapers/domain_specific_endnotes.pdf][Endnotes]])

** [[file:notebooks/day5/01-mlops-for-generative-ai.org][Day 5: MLOps for Generative AI]]

- MLOps practices adapted for Generative AI
- Vertex AI tools for foundation models
- AgentOps for agentic applications
- Resources:
  - [[https://www.kaggle.com/whitepaper-operationalizing-generative-ai-on-vertex-ai-using-mlops][Whitepaper: Operationalizing Generative AI on Vertex AI using MLOps]]
  - [[https://github.com/GoogleCloudPlatform/agent-starter-pack][Agent Starter Pack]] (goo.gle/agent-starter-pack)

** Get Help & Community

- Join the course Discord for live discussions
- Check the [[file:examples/][examples/]] directory for additional code samples 
- For contributors: see [[file:DEVELOPMENT.org][Development Guide]]
- Submit issues if you find bugs or have enhancement ideas

** Helpful Commands

| Command            | Description                              |
|--------------------+------------------------------------------|
| ~make setup~       | Setup Python environment with Poetry     |
| ~make dev~         | Start Poetry shell for development       |
| ~make api-test~    | Test API connectivity with Gemini        |
| ~make build~       | Tangle all Org files to source code      |
| ~make tangle~      | Tangle a specific Org file (FILE=path)   |
| ~make help~        | Show all available make commands         |

** Course Resources

#+ATTR_HTML: :width 100% :alt Generative AI Course Resources
[[file:images/gemini/network-visualizations/wave-pattern-blue-purple-gemini.jpeg]]

- Whitepapers: See ~whitepapers/~ directory for all course whitepapers and endnotes
- Google AI Studio: https://makersuite.google.com/
- Gemini API Documentation: https://ai.google.dev/
- Kaggle Codelabs: https://kaggle.com/learn/5-day-genai-intensive 
- Course Livestreams: See ~livestreams/~ directory or YouTube playlist
- NotebookLM: https://notebooklm.google/ (for interactive whitepaper exploration)


** License

This project is licensed under the MIT License - see the LICENSE file for details.
